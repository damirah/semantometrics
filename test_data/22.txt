altmetrics: a manifesto
No one can read everything.  We rely on filters to make sense of the scholarly literature, but the narrow, traditional filters are being swamped. However, the growth of new, online scholarly tools allows us to make new filters; these altmetrics reflect the broad, rapid impact of scholarship in this burgeoning ecosystem. We call for more tools and research based on altmetrics.
As the volume of academic literature explodes, scholars rely on filters to select the most relevant and significant sources from the rest. Unfortunately, scholarship’s three main filters for importance are failing:
Peer-review has served scholarship well, but is beginning to show its age. It is slow, encourages conventionality, and fails to hold reviewers accountable. Moreover, given that most papers are eventually published somewhere, peer-review fails to limit the volume of research.
Citation counting measures are useful, but not sufficient. Metrics like the h-index are even slower than peer-review: a work’s first citation can take years.  Citation measures are narrow;  influential work may remain uncited.  These metrics are narrow; they neglect impact outside the academy, and also ignore the context and reasons for citation.
The JIF, which measures journals’ average citations per article, is often incorrectly used to assess the impact of individual articles.  It’s troubling that the exact details of the JIF are a trade secret, and that  significant gaming is relatively easy.
