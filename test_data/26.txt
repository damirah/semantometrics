Open Mirror Feasibility Study, Appendix A: Technical Prototyping Report
The technical prototyping report focuses on the key technical implementation challenges involved in providing an Open Mirror service as well as possible solutions. The report consists of three main parts.
Part 1 – Open Mirror Use Cases, Component Prototype and Technical Challenges
Section 1
The first section outlines the Open Mirror component prototype built by EDINA which explored access to and licensing conditions for Gold OA content. The prototype harvested metadata from UK Pure systems (using a dataset of records with full-text), resolved the DOI for each record and searched for Creative Commons licence information in the metadata embedded in the publisher’s full-text HTML. Given that many records in CRIS and repositories are metadata only, the prototype therefore points towards a potential mechanism for identifying OA status of articles (currently a potential issue for OA aggregation of Gold content). The system also linked to RoMEO and Gateway to Research data. An investigation of Creative Commons licenses for articles in the CRIS systems harvested revealed that availability and expression of licences varies significantly. Possible extensions to the prototype could include subject faceted searching, reporting options for individual institutions, inclusion of additional available funder information, inclusion of records that do not have full text, as well as potential extension to include records from institutional repositories. 
Section 2
The second section presents a set of nine aggregation use cases, together with discussion of the technical challenges to be addressed; it highlights some of the gold OA issues. As indicated, filtering content so that only OA resources are retrieved is a known problem, further complicated by the existence of hybrid journals. If it is decided to restrict scope to the UK then, Open Mirror adds the challenge of filtering UK content only. Publisher metadata does not yet specify the Open Access status of an article or the author’s institutional affiliation. An ongoing problem for aggregators is that both institutional repositories and publishers employ different methods for linking from identifiers exposed in metadata to full text content – some link directly to the resource while others use landing pages to provide the link. This reduces automation and requires per-platform customisation. CORE has developed a strategy to overcome the problem, which involves assigning a ‘harvesting level’ to a repository depending on the way it manages linking, which in turn determines the procedure used by CORE. Approaches used by ResourceSync (if adopted), and also LOCKSS and the CrossRef PROSPECT project could potentially offer different solutions here. Aggregators also face the major issue of providing clear legal permissions for redistribution of full text content; the complexity of licencing results in some institutions offering contradictory statements for reuse of repository content. In part 2 the legality of aggregating publicly available content (as opposed to open access content) is briefly explored; the Open Mirror legal review covers this in detail. While a number of Open Mirror consultation responses indicated a demand for full text in XML format to support text mining, no repositories and only a few publishers (eg PLOS One, Springer, EuropePMC) currently offer full-text XML versions as standard. However it is likely that other publishers have the technical capacity to provide XML. Preservation issues to be tackled include deciding if the collection to be preserved would be the Open Mirror aggregation, institutional repositories or the published journals. The same question applies to the use case addressing improvement in SEO rankings – is SEO sought for Open Mirror or individual repository collections? The CORE service demonstrates that it is possible to achieve good rankings for a full-text aggregation. Several use cases could be supported by dashboard type facilities which would allow (1) repository managers to monitor the availability and quality of their data, and enable benchmarking against others e.g. the proportion of full text versus metadata only records (2) researchers to confirm that their articles are Open Access and fully available under the terms agreed with the publisher and required by the funder (3) Jisc to measure and assess rate of full-text deposit within institutional repositories, usage of repository content, take-up of standards and use of software and profiles (4) Research Councils to discover what research outputs they have funded (5) Research Councils and Researchers to discover the impact of their outputs (eg based on usage, citations and impact factor of publication). High quality, consistent (and potentially rich) metadata, containing an explicit link to downloadable and machine readable full-text, across both institutional repositories and publishers is unsurprisingly a key recurring requirement to support most of the use cases identified. 
Part 2 – Harvesting From Current Research Information Systems
Current Research Information System (CRIS) portals are becoming an additional harvesting target for aggregators, especially since some institutions using the Pure system are starting to use the CRIS to provide repository functionality. This may be a growing trend for the 21 Pure implementations in the UK; the debate over CRIS and institutional repository platform functionality is ongoing. Part 2 of the report briefly surveys the UK research information management landscape and identifies the systems involved. The issue of CRIS compliance with OAI-PMH is examined and Pure timescales for developing compliance noted. Symplectic Elements, which is widely used in the UK for publications management, does not support OAI-PMH harvesting. Some institutions which use an institutional repository and a CRIS to provide different services, may offer two OAI-PMH end points in future, depending on local requirements. 
Part 3 – Technical Feasibility Review
The third part focuses on harvesting from institutional repositories in particular and the range of issues that need to be addressed in order to successfully implement a full text aggregation service for UK (and wider) user communities. Therefore the opportunities and limitations of OAIPMH, as the current de facto protocol for harvesting records from OA repositories, are examined in some detail. Metadata harvesting issues include deciding the frequency of aggregation updates, the varying methods for maintaining records about deleted records and difficulties harvesting from very large repositories. Addressing the problem of linking from metadata to full text, this time for repositories, a dereferencable identifier is proposed which would resolve to the version of the record held in the repository; a similar solution is recommended in the RIOXX application profile although RIOXX specifies that there can only be one dc: identifier in a Dublin Core record. In addition, metadata validation tools for repository managers are needed. As incentives for compliance with good practice for exposing metadata, aggregations can offer value added services for repositories eg increased visibility, benchmarking etc. In the absence of a widely accepted standard for identifying OA content in repositories, the different approaches adopted by OpenAIRE and RIOXX are compared, as well as the creation of open access sets in OAI-PMH (as deployed by arXiv.org and PubMed Central), none of which are straightforward. Similarly, automated identification of open access content in hybrid journals is also a prerequisite for aggregation. A short survey revealed that some large publishers cannot provide this identification and are reluctant to cooperate on improving current technical infrastructures, whereas small OA publishers offer better services. Given OA identification difficulties, harvesting systems need strategies for responding to take-down requests. The restrictions imposed by some content providers to prevent web crawlers (apart from eg Googlebot) from accessing content is a big issue for harvesting services. Possible approaches identified are (1) mandate content accessibility for machines; (2) ask individual repositories to add an exception for a specific robot; (3) ignore the Robots Exclusion Standard; (4) mimic a permitted search engine. Clearly, the last two options pose significant risks. A further OAI-PMH issue relating specifically to content harvesting (rather than just metadata) is the lack of any mechanism to notify aggregators of changes to the full-text unless the metadata record itself has changed. As a consequence aggregators are forced to reharvest all content on a periodic basis - a very expensive solution. Harvesters also face specific issues when full text content is no longer available, is available on an external website (instead of in the local repository) or is embargoed. A potential barrier to comprehensive harvesting is that some repository managers fear that aggregations may negatively affect their statistics, which may in turn have funding consequences. CORE has received occasional requests from repositories and publishers not to be harvested; this opposes the primary purpose of repositories, in opening up and disseminating research outputs. However the IRUS-UK software can be installed in aggregators, enabling the benchmarking of repository download statistics. Aggregators also need to provide appropriate access to content for text miners including eg harmonisation and provision of structured markup such as XML. The report presents some estimates of the numbers of OA articles available in the UK and also worldwide – figures range from 5 to 21 million articles. These results allow hardware resource requirements to be estimated in turn. Rapid growth is also predicted, based partly on the new OA mandates. BASE statistics also show that the number of records in repositories doubled in four years (2009-2012); the same could happen again, therefore doubling required storage space and increasing costs. A distributed infrastructure is envisaged, which could be built across organisational and geographic boundaries. Options for providing access to the dataset eg for text mining are addressed. Finally the report looks at the development effort required to build other aggregator services such as OAISter, which is metadata only. However since CORE has already developed a national aggregator, UK Open Mirror costs would be restricted to ongoing sustainability rather than setup costs in addition. As community systems mature and enabling standards become more widely implemented, there is likely to be scope for more sophisticated services. Experience also shows that once a powerful backbone infrastructure is established, development of tools on top of it is inexpensive. The report concludes that building a large scale aggregator of Open Access content is certainly possible, although potentially complex. The level of complexity and resulting systems costs will be determined by Open Mirror’s approach to overcoming the range of technical obstacles identified. 
